{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJRc+AWojtH46x7FqfmLIj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","# Find the latest version of spark 3.x from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","spark_version = 'spark-3.4.0'\n","os.environ['SPARK_VERSION'] = spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()\n","\n","# Import required PySpark functions\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import avg, round\n","import time\n","\n","# Create a SparkSession\n","spark = SparkSession.builder.appName(\"HomeSales\").getOrCreate()\n","\n","# 1. Read in the AWS S3 bucket into a DataFrame.\n","from pyspark import SparkFiles\n","url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n","spark.sparkContext.addFile(url)\n","df = spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"), header=True, inferSchema=True)\n","\n","# 2. Create a temporary view of the DataFrame.\n","df.createOrReplaceTempView(\"home_sales\")\n","\n","# 3. What is the average price for a four-bedroom house sold per year, rounded to two decimal places?\n","query_1 = \"\"\"\n","SELECT date_format(date, 'yyyy') as year,\n","       ROUND(AVG(price), 2) as avg_price\n","FROM home_sales\n","WHERE bedrooms = 4\n","GROUP BY year\n","ORDER BY year\n","\"\"\"\n","spark.sql(query_1).show()\n","\n","# 4. What is the average price of a home for each year the home was built,\n","# that have 3 bedrooms and 3 bathrooms, rounded to two decimal places?\n","query_2 = \"\"\"\n","SELECT date_built,\n","       ROUND(AVG(price), 2) as avg_price\n","FROM home_sales\n","WHERE bedrooms = 3 AND bathrooms = 3\n","GROUP BY date_built\n","ORDER BY date_built\n","\"\"\"\n","spark.sql(query_2).show()\n","\n","# 5. What is the average price of a home for each year the home was built,\n","# that have 3 bedrooms, 3 bathrooms, with two floors, and are greater than or equal to 2,000 square feet,\n","# rounded to two decimal places?\n","query_3 = \"\"\"\n","SELECT date_built,\n","       ROUND(AVG(price), 2) as avg_price\n","FROM home_sales\n","WHERE bedrooms = 3 AND bathrooms = 3 AND floors = 2 AND sqft_living >= 2000\n","GROUP BY date_built\n","ORDER BY date_built\n","\"\"\"\n","spark.sql(query_3).show()\n","\n","# 6. What is the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000? Order by descending view rating.\n","# Determine the runtime for this query.\n","start_time = time.time()\n","\n","query_4 = \"\"\"\n","SELECT view,\n","       ROUND(AVG(price), 2) as avg_price\n","FROM home_sales\n","GROUP BY view\n","HAVING AVG(price) >= 350000\n","ORDER BY avg_price DESC\n","\"\"\"\n","spark.sql(query_4).show()\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))\n","\n","# 7. Cache the the temporary table home_sales.\n","spark.catalog.cacheTable(\"home_sales\")\n","\n","# 8. Check if the table is cached.\n","spark.catalog.isCached('home_sales')\n","\n","# 9. Using the cached data, run the last query above, that calculates\n","# the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000.\n","# Determine the runtime and compare it to the uncached runtime.\n","start_time = time.time()\n","\n","spark.sql(query_4).show()\n","\n","print(\"--- Cached query runtime: %s seconds ---\" % (time.time() - start_time))\n","\n","# 10. Partition by the \"date_built\" field on the formatted parquet home sales data\n","df.write.mode(\"overwrite\").partitionBy(\"date_built\").parquet(\"home_sales_parquet\")\n","\n","# 11. Read the parquet formatted data.\n","parquet_df = spark.read.parquet(\"home_sales_parquet\")\n","\n","# 12. Create a temporary table for the parquet data.\n","parquet_df.createOrReplaceTempView(\"parquet_home_sales\")\n","\n","# 13. Using the parquet DataFrame, run the last query above, that calculates\n","# the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000.\n","# Determine the runtime and compare it to the cached runtime.\n","start_time = time.time()\n","\n","spark.sql(query_4).show()\n","\n","print(\"--- Parquet query runtime: %s seconds ---\" % (time.time() - start_time))\n","\n","# 14. Uncache the home_sales temporary table.\n","spark.catalog.uncacheTable(\"home_sales\")\n","\n","# 15. Check if the home_sales is no longer cached.\n","spark.catalog.isCached(\"home_sales\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKSZxwSG7Ljd","executionInfo":{"status":"ok","timestamp":1725955324671,"user_tz":420,"elapsed":16730,"user":{"displayName":"Shahid Syed","userId":"01544321108702179914"}},"outputId":"8bd386b3-1826-4d06-eb5b-5613489276ef"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [Connected to r2u.stat\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Ign:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy Release\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","tar: spark-3.4.0-bin-hadoop3.tgz: Cannot open: No such file or directory\n","tar: Error is not recoverable: exiting now\n","+----+---------+\n","|year|avg_price|\n","+----+---------+\n","|2019| 300263.7|\n","|2020|298353.78|\n","|2021|301819.44|\n","|2022|296363.88|\n","+----+---------+\n","\n","+----------+---------+\n","|date_built|avg_price|\n","+----------+---------+\n","|      2010|292859.62|\n","|      2011|291117.47|\n","|      2012|293683.19|\n","|      2013|295962.27|\n","|      2014|290852.27|\n","|      2015| 288770.3|\n","|      2016|290555.07|\n","|      2017|292676.79|\n","+----------+---------+\n","\n","+----------+---------+\n","|date_built|avg_price|\n","+----------+---------+\n","|      2010|285010.22|\n","|      2011|276553.81|\n","|      2012|307539.97|\n","|      2013|303676.79|\n","|      2014|298264.72|\n","|      2015|297609.97|\n","|      2016| 293965.1|\n","|      2017|280317.58|\n","+----------+---------+\n","\n","+----+----------+\n","|view| avg_price|\n","+----+----------+\n","|  91|1137372.73|\n","|  97|1129040.15|\n","|  84|1117233.13|\n","|  75|1114042.94|\n","|  89|1107839.15|\n","|  78|1080649.37|\n","|  77|1076205.56|\n","|  87| 1072285.2|\n","|  86|1070444.25|\n","|  82| 1063498.0|\n","|  90|1062654.16|\n","|  99|1061201.42|\n","|  76|1058802.78|\n","|  85|1056336.74|\n","|  95| 1054325.6|\n","|  98|1053739.33|\n","|  81|1053472.79|\n","|  83|1033965.93|\n","|  94| 1033536.2|\n","|  88|1031719.35|\n","+----+----------+\n","only showing top 20 rows\n","\n","--- 0.38077211380004883 seconds ---\n","+----+----------+\n","|view| avg_price|\n","+----+----------+\n","|  91|1137372.73|\n","|  97|1129040.15|\n","|  84|1117233.13|\n","|  75|1114042.94|\n","|  89|1107839.15|\n","|  78|1080649.37|\n","|  77|1076205.56|\n","|  87| 1072285.2|\n","|  86|1070444.25|\n","|  82| 1063498.0|\n","|  90|1062654.16|\n","|  99|1061201.42|\n","|  76|1058802.78|\n","|  85|1056336.74|\n","|  95| 1054325.6|\n","|  98|1053739.33|\n","|  81|1053472.79|\n","|  83|1033965.93|\n","|  94| 1033536.2|\n","|  88|1031719.35|\n","+----+----------+\n","only showing top 20 rows\n","\n","--- Cached query runtime: 0.509152889251709 seconds ---\n","+----+----------+\n","|view| avg_price|\n","+----+----------+\n","|  91|1137372.73|\n","|  97|1129040.15|\n","|  84|1117233.13|\n","|  75|1114042.94|\n","|  89|1107839.15|\n","|  78|1080649.37|\n","|  77|1076205.56|\n","|  87| 1072285.2|\n","|  86|1070444.25|\n","|  82| 1063498.0|\n","|  90|1062654.16|\n","|  99|1061201.42|\n","|  76|1058802.78|\n","|  85|1056336.74|\n","|  95| 1054325.6|\n","|  98|1053739.33|\n","|  81|1053472.79|\n","|  83|1033965.93|\n","|  94| 1033536.2|\n","|  88|1031719.35|\n","+----+----------+\n","only showing top 20 rows\n","\n","--- Parquet query runtime: 0.5442464351654053 seconds ---\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":9}]}]}